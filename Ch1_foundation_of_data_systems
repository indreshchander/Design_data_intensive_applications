Foundation of data systems
==========================

=> Note that a fault is not the same as a failure [2]. A fault is usually defined as one component of the system deviating from its spec, 
whereas a failure is when the system as a whole stops providing the required service to the user. 

=> Counterintuitively, in such fault-tolerant systems, it can make sense to increase the rate of faults by triggering them deliberately—for example, 
by randomly killing indi‐ vidual processes without warning. Many critical bugs are actually due to poor error handling [3]; by deliberately inducing faults, 
you ensure that the fault-tolerance machinery is continually exercised and tested, which can increase your confidence that faults will be handled correctly 
when they occur naturally. The Netflix Chaos Monkey [4] is an example of this approach.

=> Software faults are systematic faults. 

=> Set up detailed and clear monitoring, such as performance metrics and error rates. In other engineering disciplines this is referred to as telemetry. 
(Once a rocket has left the ground, telemetry is essential for tracking what is happening, and for understanding failures [14].) 
Monitoring can show us early warning signals and allow us to check whether any assumptions or constraints are being violated. 
When a problem occurs, metrics can be invaluable in diagnosing the issue.

=> The response time is what the client sees: besides the actual time to process the request (the service time), it includes network delays and queueing delays

=> Latency is the duration that a request is waiting to be handled—during which it is latent, awaiting service 

=> But even in a scenario where you’d think all requests should take the same time, you get variation: random additional latency could be 
introduced by a context switch to a background process, the loss of a network packet and TCP retransmission, a garbage collection pause, 
a page fault forcing a read from disk, mechanical vibrations in the server rack [18], or many other causes.

=> if the 95th percentile response time is 1.5 seconds, that means 95 out of 100 requests take less than 1.5 seconds, and 5 out of 100 requests 
take 1.5 seconds or more. Queueing delays often account for a large part of the response time at high percentiles. 
